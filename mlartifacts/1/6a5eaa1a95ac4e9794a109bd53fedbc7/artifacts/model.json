{
  "claim_extractor.extractor.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract the claims from the statement(s).",
      "fields": [
        {
          "prefix": "Statement:",
          "description": "the statements to extract claims from"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Claims:",
          "description": "A list of distinct claims"
        }
      ]
    },
    "lm": null
  },
  "research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.judge.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "FIRE (Fact-checking with Iterative Research and Evaluation) Judge.\n\nEvaluate a single factual claim given accumulated evidence from web research.\nEither produce a final verdict if sufficient evidence exists, or generate\na search query to gather more information.\n\nDecision logic:\n- If evidence clearly supports the claim -> verdict=\"supported\"\n- If evidence clearly contradicts the claim -> verdict=\"refuted\"\n- If evidence is insufficient but a useful search is possible -> next_search=<query>\n- If no more useful searches and evidence is inconclusive -> verdict=\"not_supported\"",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "A single factual claim to verify"
        },
        {
          "prefix": "Evidence:",
          "description": "Evidence gathered from web research, may be empty initially"
        },
        {
          "prefix": "Search History:",
          "description": "Previous search queries already executed"
        },
        {
          "prefix": "Reasoning:",
          "description": "Step-by-step reasoning about the claim and evidence"
        },
        {
          "prefix": "Verdict:",
          "description": "Final judgment if enough evidence exists, otherwise None"
        },
        {
          "prefix": "Next Search:",
          "description": "Search query if more evidence needed, otherwise None. Must differ from search_history."
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "aggregator.aggregator.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "You are given:\n- An `original_statement` (a natural language statement, possibly containing one or more factual claims).\n- A list of `claim_verdicts`, where each element is a dictionary with the keys:\n  - `claim`: a textual claim (usually derived from the original_statement).\n  - `verdict`: one of {'supported', 'not_supported', 'refuted'}.\n  - `evidence_summary`: a text summary of evidence and/or search results used to evaluate that claim (may be empty or contain irrelevant details).\n\nYour task is to aggregate the individual claim verdicts into:\n1. A short natural language explanation of how you applied the aggregation rule (`reasoning`).\n2. A single label for the entire original_statement (`overall_verdict`).\n3. A confidence score between 0 and 1 (`confidence`).\n\n### Input format\n\nYou will be given something equivalent to:\n\n- `original_statement`: string\n\n- `claim_verdicts`: list[dict], for example:\n  [\n    {\n      \"claim\": \"<string>\",\n      \"verdict\": \"supported\" | \"not_supported\" | \"refuted\",\n      \"evidence_summary\": \"<string, may be empty>\"\n    },\n    ...\n  ]\n\nDo **not** re-evaluate the factual claims yourself. Treat each `verdict` value in `claim_verdicts` as already correct, regardless of the evidence text or your external knowledge. For example:\n- If `verdict` is \"supported\" but the evidence_summary looks weak or empty, you must still treat it as supported.\n- If `verdict` is \"not_supported\" because no evidence was found, you must still treat it as not_supported.\n- If `verdict` is \"refuted\", treat it as refuted even if you personally believe the claim might be true.\n\nThe aggregation is purely mechanical over the provided `verdict` fields.\n\n### Aggregation logic (priority order)\n\nApply this logic to produce `overall_verdict`:\n\n1. If **any** claim in `claim_verdicts` has `verdict == \"refuted\"`, then:\n   - `overall_verdict = \"CONTAINS_REFUTED_CLAIMS\"`\n   - This is the **highest priority** and overrides all other conditions.\n\n2. Else, if **any** claim has `verdict == \"not_supported\"`, then:\n   - `overall_verdict = \"CONTAINS_UNSUPPORTED_CLAIMS\"`\n\n3. Else, if **all** claims have `verdict == \"supported\"`, then:\n   - `overall_verdict = \"SUPPORTED\"`\n\nYou will **always** produce one of these three labels:\n- `CONTAINS_REFUTED_CLAIMS`\n- `CONTAINS_UNSUPPORTED_CLAIMS`\n- `SUPPORTED`\n\nDo **not** invent or use any other overall labels (such as UNKNOWN, NEI, etc.).\n\n### Reasoning guidelines\n\n- In `reasoning`, explicitly reference how the individual claim verdicts trigger the aggregation rules above.\n- You **may** restate the original claim(s) briefly to clarify, but keep it concise.\n- Focus on the status of the claims, not on re-arguing the evidence. For example:\n  - If there is a single claim with verdict \"supported\": explain that since all claims are supported, the overall verdict is \"SUPPORTED\".\n  - If there is at least one \"not_supported\" and no \"refuted\": explain that the presence of at least one unsupported claim leads to \"CONTAINS_UNSUPPORTED_CLAIMS\".\n  - If there is at least one \"refuted\": explain that any refuted claim leads to \"CONTAINS_REFUTED_CLAIMS\", regardless of other supported claims.\n\nDo **not**:\n- Override or reinterpret the given per-claim verdicts based on your own world knowledge or the evidence_summary.\n- Introduce new claims.\n- Change the priority order of the rules.\n\n### Confidence\n\n- Output `confidence` as a floating-point number between 0 and 1.\n- Since the task is a straightforward rule-based aggregation, you can generally use a high confidence such as:\n  - 1.0 if the aggregation is unambiguous (typical when all verdicts are clearly one category or the priority rule is straightforward to apply).\n  - Slightly less than 1.0 only if the input is malformed or ambiguous (e.g., empty list of claim_verdicts, missing fields, or unexpected verdict labels). In such edge cases, explain this in the reasoning.\n\n### Output format\n\nReturn a JSON-like structure with exactly these top-level keys:\n\n- `reasoning`: a short paragraph (2â€“5 sentences) explaining how you applied the aggregation rules to the given claim_verdicts.\n- `overall_verdict`: one of \"CONTAINS_REFUTED_CLAIMS\", \"CONTAINS_UNSUPPORTED_CLAIMS\", or \"SUPPORTED\".\n- `confidence`: a numeric value between 0 and 1.\n\nExample template:\n\nreasoning\n<your explanation here>\n\noverall_verdict\n<one of the three allowed labels>\n\nconfidence\n<your numeric confidence>",
      "fields": [
        {
          "prefix": "Original Statement:",
          "description": "The original statement being evaluated"
        },
        {
          "prefix": "Claim Verdicts:",
          "description": "List of dicts with 'claim', 'verdict', and 'evidence_summary' keys"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of the aggregation logic applied"
        },
        {
          "prefix": "Overall Verdict:",
          "description": "The final verdict for the entire statement"
        },
        {
          "prefix": "Confidence:",
          "description": "Confidence score between 0.0 and 1.0"
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.11",
      "dspy": "3.0.4",
      "cloudpickle": "3.1"
    }
  }
}
