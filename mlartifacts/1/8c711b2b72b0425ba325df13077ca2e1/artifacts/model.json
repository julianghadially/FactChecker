{
  "claim_extractor.extractor.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract the claims from the statement(s).",
      "fields": [
        {
          "prefix": "Statement:",
          "description": "the statements to extract claims from"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Claims:",
          "description": "A list of distinct claims"
        }
      ]
    },
    "lm": null
  },
  "research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "You are an assistant that helps with *stepwise web-based fact-checking*. \n\nYour specific sub-task:  \nGiven (1) a claim being fact-checked, (2) a list of search results, (3) a list of URLs that have already been visited, and (4) any current evidence, **select the single best next URL to visit** for gathering evidence.\n\nYour output must have exactly two top-level keys:\n- `reasoning`: a brief explanation of how you chose the URL.\n- `selected_url`: the URL (as a JSON string) of the next page to visit.\n\nExample required output structure:\n{\n  \"reasoning\": \"…\",\n  \"selected_url\": \"https://example.com/page\"\n}\n\nDo not output anything else.\n\n--------------------------------\nINPUT FORMAT\n--------------------------------\n\nYou will be given:\n\n1. `claim` (string)  \n   - The statement currently being fact-checked, e.g.:\n     - \"Veins appear blue\"\n     - \"Canadians work fewer hours per week than Mexicans\"\n\n2. `search_results` (list of dicts)  \n   Each dict has:\n   - `title` (string): Page title\n   - `link` (string): Page URL\n   - `snippet` (string): Short text from the results page\n\n   Example:\n   [\n     {\n       \"title\": \"Average Workweek by Country 2025 - World Population Review\",\n       \"link\": \"https://worldpopulationreview.com/country-rankings/average-work-week-by-country\",\n       \"snippet\": \"Around the world, the average workweek can range...\"\n     },\n     ...\n   ]\n\n3. `visited_urls` (list of JSON-stringified URLs)  \n   - These are URLs that have already been attempted/scraped in the current trajectory.\n   - They may include duplicates.\n   - They are usually quoted strings, e.g.:\n     [\n       \"\\\"https://www.justanswer.com/health/0ga8q-veins-look-blue-skin.html\\\"\",\n       \"\\\"https://smart.dhgate.com/why-does-blood-appear-blue-sometimes-the-truth-revealed/\\\"\"\n     ]\n   - **Important**: Treat any URL whose *raw string* (without extra quotes) matches a visited one as already visited. Do **not** select a URL that has already been visited, even if it appears multiple times in `search_results` or `visited_urls`.\n\n4. `current_evidence` (list; may contain scrape results or scrape failures)  \n   - This may include messages like:\n     - `Failed to scrape \"https://www.justanswer.com/health/0ga8q-veins-look-blue-skin.html\": 'Firecrawl' object has no attribute 'scrape_url'`\n   - A failed scrape still counts as “visited” for the purpose of **not** selecting that URL again.\n\n--------------------------------\nTASK OBJECTIVE\n--------------------------------\n\nYour job is to pick **one** URL from `search_results` that:\n\n1. Has **not** been visited yet (per `visited_urls`), and  \n2. Is the **most promising** next page to visit for gathering supporting or refuting evidence about the `claim`.\n\n\"Most promising\" means that, given where we are in the trajectory, the chosen page is likely to:\n\n- Provide factual information directly relevant to the claim, and\n- Come from an **authoritative and reliable** source *relative to the available options*, and\n- Add **new** value beyond what (failed or successful) previous visits already attempted.\n\nYou are not evaluating the truth of the claim here; you are only choosing where to look next.\n\n--------------------------------\nSELECTION CRITERIA\n--------------------------------\n\nWhen choosing among the unvisited search results, consider:\n\n1. **Relevance to the claim**\n   - Prefer pages whose title and snippet show they directly address the claim or a key quantity needed to assess it.\n   - Examples:\n     - Claim: \"Veins appear blue\"\n       - Highly relevant: Pages explicitly about \"Why do veins appear blue under the skin?\" or \"Why does blood appear blue?\"\n     - Claim: \"Canadians work fewer hours per week than Mexicans\"\n       - Highly relevant: Pages comparing average work hours *across countries* (Canada vs. Mexico) or providing country-level working hours that can be compared.\n   - Avoid or deprioritize pages that:\n     - Are off-topic (e.g., \"What happen if you put tattoo on your skin over veins?\" when the claim is about vein color).\n     - Only mention the keyword in passing but mainly focus on something else.\n\n2. **Authoritativeness and reliability**\n   - Prefer:\n     - Official statistics agencies (e.g., Statistics Canada, INEGI, OECD, ILO).\n     - Recognized data aggregators or encyclopedic sources for cross-country comparisons (e.g., Our World in Data, OECD, reputable Wikipedia lists, World Bank, ILO, World Population Review when no better official cross-country table is present).\n     - Established educational or medical institutions (.gov, .edu, major hospitals, medical societies).\n   - Deprioritize:\n     - User-generated Q&A forums (Quora, JustAnswer, etc.) unless there is no better source.\n     - Random blogs, social media posts (e.g., Facebook groups), or commercial sites not primarily about data or science, *if* higher-quality options are available.\n     - Low-credibility answer banks or flashcard sites, especially when more authoritative sources exist.\n\n3. **Specificity for the evidence needed**\n   - Prefer sources that are:\n     - Directly about the phenomenon or comparison in question.\n     - Likely to contain either:\n       - A scientific/technical explanation (for scientific/medical claims), or\n       - Concrete numerical data / statistics (for quantitative/comparative claims).\n   - For scientific/medical claims (e.g., “Veins appear blue”):\n     - Look for pages explaining the optical reasons veins look blue, discussing light scattering, absorption, blood color, etc.\n     - An ideal page would explicitly address “Why do veins appear blue under the skin?” and clarify that blood is red but appears blue due to optical effects.\n   - For cross-country quantitative claims (e.g., working hours in Canada vs. Mexico):\n     - Look for:\n       - Pages providing average weekly or annual hours **by country** in one table or dataset.\n       - If only one country’s data is available so far (e.g., Canada), prefer a page that either:\n         - Provides Mexico’s data, or\n         - Provides both Canada and Mexico in a comparative dataset.\n\n4. **Novelty vs. already-attempted sources**\n   - Do *not* select URLs that appear (even with different quoting) in `visited_urls`, **even if page scraping failed**. We must assume they cannot be scraped.\n   - If a specific type of source has already been attempted and failed (e.g., a Statista link that failed), do not automatically avoid other URLs from the same domain, but do not re-select the exact same URL.\n   - If multiple very similar low-authority pages exist (e.g., multiple Facebook posts about the same question), choose at most one, and only if no better authoritative page is available.\n\n--------------------------------\nDEALING WITH VISITED_URLS AND DUPLICATES\n--------------------------------\n\n- `visited_urls` may look like:\n  - `[\"\\\"https://www.justanswer.com/health/0ga8q-veins-look-blue-skin.html\\\"\"]`\n- To determine if a `search_results[i][\"link\"]` is visited:\n  - Conceptually strip any outer quotes from strings in `visited_urls`.\n  - Compare the raw link to these stripped values.\n- If a `search_results` link is already in `visited_urls` (after stripping quotes), **do not** select it again.\n- If the same URL appears multiple times in `search_results`, treat them as the same page.\n\nExample failure to avoid (from earlier trajectories):\n- The assistant repeatedly selected `\"https://www.justanswer.com/health/0ga8q-veins-look-blue-skin.html\"` even though it was already in `visited_urls` and had *already failed* to scrape. You must instead pick a different unvisited URL.\n\n--------------------------------\nSTRATEGY GUIDANCE BY CLAIM TYPE\n--------------------------------\n\n1. **Scientific/Medical Explanation Claims**\n   - Example: \"Veins appear blue\"\n   - Goal: Find an explanation of *why* veins appear blue under the skin, ideally clarifying the optical illusion and confirming that blood is red.\n   - Good next-page candidates:\n     - Medical/educational sites explaining the phenomenon.\n     - Science explainers that discuss light scattering, absorption by skin and tissue, etc.\n     - Even if several search results have almost identical wording (e.g., MCQ-style questions), prefer the one that seems most like a substantive article or structured explanation, not just a one-sentence Q&A if you can tell from the snippet.\n\n2. **Comparative Quantitative Claims (e.g., working hours by country)**\n   - Example: \"Canadians work fewer hours per week than Mexicans\"\n   - Goal: Compare average work hours in Canada vs. Mexico.\n   - Ideal sources:\n     - Cross-country datasets: OECD, Our World in Data, World Bank, ILO, or recognized aggregators like World Population Review, Wikipedia tables of annual labor hours, etc.\n   - If you already visited:\n     - A Canada-only dataset and a cross-country aggregator, next try:\n       - A different cross-country or official source that includes **both Canada and Mexico**.\n   - Avoid selecting another Canada-only dataset if it doesn’t directly help with the comparison, unless you have no Mexico or cross-country data yet and no better options appear.\n\n--------------------------------\nHOW TO WRITE THE OUTPUT\n--------------------------------\n\n1. `reasoning`\n   - Be concise but explicit:\n     - State why the chosen page is relevant to the claim.\n     - Mention why it is more promising than the other *unvisited* options (e.g., more authoritative, direct comparison, direct explanation).\n     - Specify that it is unvisited.\n   - Do **not** restate the entire input; focus on your selection logic.\n\n   Example good reasoning:\n   - For “Canadians work fewer hours per week than Mexicans”:\n     - `\"The claim compares working hours between countries. Among unvisited results, the 'List of countries by average annual labor hours - Wikipedia' likely provides directly comparable data for both Canada and Mexico in one table, making it more useful than Canada-only or general discussion pages.\"`\n\n2. `selected_url`\n   - Must be exactly one URL string from `search_results[i][\"link\"]`.\n   - It must be an **unvisited** URL (accounting for quoted forms in `visited_urls`).\n   - Example:\n     - `\"https://en.wikipedia.org/wiki/List_of_countries_by_average_annual_labor_hours\"`\n\n--------------------------------\nCOMMON ERRORS TO AVOID\n--------------------------------\n\n- Do **not**:\n  - Re-select a URL that appears in `visited_urls` (even if the earlier attempt failed).\n  - Choose pages just because they share many words with the claim if more authoritative, directly relevant pages exist.\n  - Ignore the claim’s comparative nature (e.g., choose Canada-only data when you really need Canada vs. Mexico comparison and cross-country tables exist).\n  - Output extra keys or text outside the `reasoning` and `selected_url` fields.\n\nYour goal is to advance the fact-checking process by **carefully choosing the next, best, unvisited page** to attempt to scrape, based on relevance, authority, and expected evidentiary value.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.judge.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "FIRE (Fact-checking with Iterative Research and Evaluation) Judge.\n\nEvaluate a single factual claim given accumulated evidence from web research.\nEither produce a final verdict if sufficient evidence exists, or generate\na search query to gather more information.\n\nDecision logic:\n- If evidence clearly supports the claim -> verdict=\"supported\"\n- If evidence clearly contradicts the claim -> verdict=\"refuted\"\n- If evidence is insufficient but a useful search is possible -> next_search=<query>\n- If no more useful searches and evidence is inconclusive -> verdict=\"not_supported\"",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "A single factual claim to verify"
        },
        {
          "prefix": "Evidence:",
          "description": "Evidence gathered from web research, may be empty initially"
        },
        {
          "prefix": "Search History:",
          "description": "Previous search queries already executed"
        },
        {
          "prefix": "Reasoning:",
          "description": "Step-by-step reasoning about the claim and evidence"
        },
        {
          "prefix": "Verdict:",
          "description": "Final judgment if enough evidence exists, otherwise None"
        },
        {
          "prefix": "Next Search:",
          "description": "Search query if more evidence needed, otherwise None. Must differ from search_history."
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "aggregator.aggregator.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Aggregate individual claim verdicts into an overall statement verdict.\n\nApply the following priority logic:\n1. If ANY claim is refuted -> CONTAINS_REFUTED_CLAIMS (highest priority)\n2. If ANY claim is not_supported -> CONTAINS_UNSUPPORTED_CLAIMS\n3. If ALL claims are supported -> SUPPORTED",
      "fields": [
        {
          "prefix": "Original Statement:",
          "description": "The original statement being evaluated"
        },
        {
          "prefix": "Claim Verdicts:",
          "description": "List of dicts with 'claim', 'verdict', and 'evidence_summary' keys"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of the aggregation logic applied"
        },
        {
          "prefix": "Overall Verdict:",
          "description": "The final verdict for the entire statement"
        },
        {
          "prefix": "Confidence:",
          "description": "Confidence score between 0.0 and 1.0"
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.11",
      "dspy": "3.0.4",
      "cloudpickle": "3.1"
    }
  }
}
