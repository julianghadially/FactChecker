{
  "claim_extractor.extractor.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract the claims from the statement(s).",
      "fields": [
        {
          "prefix": "Statement:",
          "description": "the statements to extract claims from"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Claims:",
          "description": "A list of distinct claims"
        }
      ]
    },
    "lm": null
  },
  "research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.judge.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "FIRE (Fact-checking with Iterative Research and Evaluation) Judge.\n\nEvaluate a single factual claim given accumulated evidence from web research.\nEither produce a final verdict if sufficient evidence exists, or generate\na search query to gather more information.\n\nDecision logic:\n- If evidence clearly supports the claim -> verdict=\"supported\"\n- If evidence clearly contradicts the claim -> verdict=\"refuted\"\n- If evidence is insufficient but a useful search is possible -> next_search=<query>\n- If no more useful searches and evidence is inconclusive -> verdict=\"not_supported\"",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "A single factual claim to verify"
        },
        {
          "prefix": "Evidence:",
          "description": "Evidence gathered from web research, may be empty initially"
        },
        {
          "prefix": "Search History:",
          "description": "Previous search queries already executed"
        },
        {
          "prefix": "Reasoning:",
          "description": "Step-by-step reasoning about the claim and evidence"
        },
        {
          "prefix": "Verdict:",
          "description": "Final judgment if enough evidence exists, otherwise None"
        },
        {
          "prefix": "Next Search:",
          "description": "Search query if more evidence needed, otherwise None. Must differ from search_history."
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "aggregator.aggregator.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "You are given:\n- An `original_statement` (a single natural-language statement).\n- A list of `claim_verdicts`, where each element is a dictionary with at least:\n  - `claim`: the text of a claim extracted from the original statement\n  - `verdict`: one of {\"supported\", \"not_supported\", \"refuted\"}\n  - `evidence_summary`: a (possibly empty) text summary of evidence used to assess that claim\n\nYour task is to aggregate the individual claim verdicts into a single overall verdict for the entire `original_statement`, and to provide a short explanation and a confidence score.\n\n## Core aggregation logic\n\nApply *only* the following priority logic to determine the `overall_verdict`:\n\n1. If **any** claim in `claim_verdicts` has `verdict == \"refuted\"`  \n   → `overall_verdict = \"CONTAINS_REFUTED_CLAIMS\"` (highest priority).\n\n2. Else, if **any** claim in `claim_verdicts` has `verdict == \"not_supported\"`  \n   → `overall_verdict = \"CONTAINS_UNSUPPORTED_CLAIMS\"`.\n\n3. Else, if **all** claims in `claim_verdicts` have `verdict == \"supported\"`  \n   → `overall_verdict = \"SUPPORTED\"`.\n\nDo **not** invent or use any additional verdict categories. The final overall verdict must be exactly one of:\n- `SUPPORTED`\n- `CONTAINS_UNSUPPORTED_CLAIMS`\n- `CONTAINS_REFUTED_CLAIMS`\n\nAssume:\n- The claim-level verdicts are already correctly determined by some previous process.\n- You must **only** aggregate; you are **not** re-evaluating factual correctness yourself.\n- Even if there is only a single claim, you must still apply the same priority logic.\n\n## Reasoning content and style\n\nProduce three outputs:\n\n1. `reasoning`  \n   - A **brief** explanation (1–3 sentences) of how you applied the priority logic to the given `claim_verdicts`.  \n   - Explicitly reference the relevant verdict categories (e.g., “There is at least one claim labeled ‘not_supported’, and none labeled ‘refuted’, so…”).  \n   - Do **not** introduce any new evidence or perform web search; base your reasoning solely on the provided `verdict` values.  \n   - Do **not** restate long evidence summaries; you may refer to them abstractly (“based on the given evidence summary”).\n\n2. `overall_verdict`  \n   - A single token/string: exactly one of `SUPPORTED`, `CONTAINS_UNSUPPORTED_CLAIMS`, or `CONTAINS_REFUTED_CLAIMS`.  \n   - This must follow the priority rules strictly (refuted > not_supported > supported).\n\n3. `confidence`  \n   - A numeric value between 0 and 1 (inclusive) indicating how confident you are that you applied the aggregation rules correctly.  \n   - Since the task is deterministic given the inputs, you will typically use a **high confidence** (e.g., `0.9`–`1.0`) unless there is some genuine ambiguity in interpreting the claim list (e.g., malformed input).\n\n## Handling multiple claims\n\n- Treat each element of `claim_verdicts` independently when checking statuses.\n- The presence of a single `refuted` claim overrides any number of `supported` or `not_supported` claims.\n- If there are no `refuted` claims but at least one `not_supported` claim, the overall verdict must be `CONTAINS_UNSUPPORTED_CLAIMS` even if all remaining claims are `supported`.\n- Only if **every** claim in the list is `supported` may you output `SUPPORTED`.\n\n## Output format\n\nReturn your results in this exact structured form (no extra commentary outside these fields):\n\n### reasoning\n[concise explanation of how you applied the rule-based aggregation]\n\n### overall_verdict\n[SUPPORTED | CONTAINS_UNSUPPORTED_CLAIMS | CONTAINS_REFUTED_CLAIMS]\n\n### confidence\n[float between 0 and 1]",
      "fields": [
        {
          "prefix": "Original Statement:",
          "description": "The original statement being evaluated"
        },
        {
          "prefix": "Claim Verdicts:",
          "description": "List of dicts with 'claim', 'verdict', and 'evidence_summary' keys"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of the aggregation logic applied"
        },
        {
          "prefix": "Overall Verdict:",
          "description": "The final verdict for the entire statement"
        },
        {
          "prefix": "Confidence:",
          "description": "Confidence score between 0.0 and 1.0"
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.11",
      "dspy": "3.0.4",
      "cloudpickle": "3.1"
    }
  }
}
