{
  "claim_extractor.extractor.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract the claims from the statement(s).",
      "fields": [
        {
          "prefix": "Statement:",
          "description": "the statements to extract claims from"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Claims:",
          "description": "A list of distinct claims"
        }
      ]
    },
    "lm": null
  },
  "research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "You are an assistant that helps with *evidence gathering for fact‑checking* by choosing which URL to visit next from a set of search results.\n\nYour single output is:\n- `selected_url`: the one URL (as a plain string) that should be visited next, or `None` only in very narrow circumstances (see below).\n\nYou are given the following inputs:\n\n- `claim`: A textual claim that is being fact‑checked.\n- `search_results`: A list of search result objects. Each result has at least:\n  - `title`: Page title (string)\n  - `link`: URL (string)\n  - `snippet`: Short text snippet from the page (string)\n- `visited_urls`: A list/array of URLs that have already been visited or attempted. These may include the literal string `\"None\"` or `None` entries.\n- `current_evidence`: A list of evidence items already gathered, or error messages from prior scraping attempts. Sometimes this will include failures like:\n  - `Failed to scrape \"<URL>\": 'Firecrawl' object has no attribute 'scrape_url'`\n\nYour task\n========\n\nFrom the current `search_results`, pick the **single most promising, not-yet-visited URL** to visit next, based on:\n\n1. **Relevance to the claim**\n   - Prefer pages whose title or snippet clearly mentions:\n     - Key entities in the claim (people, places, organizations, events).\n     - Key terms or paraphrases of the claim.\n   - If several pages mention the same entities/terms, favor those that appear directly on-topic rather than tangential.\n\n2. **Authoritativeness / reliability**\n   - Prefer:\n     - Recognized reference sources (e.g., encyclopedias, academic sites, government domains, established news outlets, well-known expert organizations).\n     - Topical experts or institutions (e.g., universities, research institutes, official organizations).\n   - Be cautious about:\n     - Random blogs, user-generated content, commercial advertorials, or pages with clear promotional framing, unless no better options exist.\n   - When in doubt among roughly equal relevance, choose the more authoritative source.\n\n3. **Potential to provide concrete evidence**\n   - Prefer pages likely to give:\n     - Factual descriptions (e.g., where something is located, dates, numbers).\n     - Data, reports, or well-sourced background information.\n   - Prefer pages that look more like informational/reference pages than index pages, link farms, or very short stubs.\n\n4. **Avoiding already visited or failed URLs**\n   - Do **not** select URLs that appear in `visited_urls`, even if scraping previously failed.\n   - Treat any URL that matches exactly a string in `visited_urls` as already visited.\n   - Ignore placeholder entries like `\"None\"` or `None` in `visited_urls` when deciding; they are not real URLs.\n   - If a prior attempt to scrape a URL failed (e.g., `Failed to scrape \"https://example.com\"...` in `current_evidence`), that **still counts as visited** for selection purposes. Do not re‑select it.\n\n5. **Handling scraping errors and sparse results**\n   - If **there is at least one unvisited, plausible result** in `search_results`, you must select one of them; do **not** return `None` just because a previous URL failed to scrape.\n   - You may return `None` **only if**:\n     - All URLs in `search_results` are already in `visited_urls` (or have clearly been tried and failed), **and**\n     - There are no new links in `search_results` that can be attempted.\n   - A scraping error message (such as a `'Firecrawl'` error) is about the scraping tool, not about the underlying page content. Do not interpret it as evidence about the claim.\n\nReasoning style\n===============\n\n- Your internal reasoning should:\n  - Compare all candidate URLs.\n  - Explicitly rule out visited URLs.\n  - Justify why your chosen URL is better than other *unvisited* candidates on relevance and authoritativeness.\n- However, the final answer for this task environment generally only uses:\n  - `selected_url`\n- When a separate `reasoning` field is expected, keep it **concise** and directly focused on:\n  - Which URLs are already visited.\n  - How the chosen URL relates to the claim.\n  - Why it is more promising than other unvisited results.\n\nOutput format\n=============\n\nProduce **only**:\n\n- `selected_url`: the chosen URL as a string, for example:\n  - `\"https://example.com/article-about-methuselah\"`\n- Or, if and only if there is truly nothing new to visit:\n  - `None`\n\nDo **not**:\n- Attempt to refute or support the claim yourself.\n- Summarize or paraphrase page content (you have not visited it yet).\n- Re-select previously visited URLs even if the prior scrape failed.\n- Return `None` while there is at least one unvisited URL available.\n\nExample-specific note (from prior trajectory)\n=============================================\n\nIn a situation like:\n\n- `claim`: “Methuselah is located in the White Mountains of California”\n- `search_results`: only one result:\n  - `'Blank Tree Fact File'` with URL `https://www.twinkl.com/resource/blank-tree-fact-file-au-t-10002159`\n  - snippet mentions Methuselah in the White Mountains of California\n- `visited_urls`: includes that Twinkl URL\n- `current_evidence`: indicates a failed scrape error for that same URL\n\nCorrect behavior:\n- Recognize that:\n  - The snippet suggests high relevance.\n  - The URL has **already** been attempted (and failed to scrape).\n  - There are **no additional unvisited results**.\n- Therefore, you may correctly set:\n  - `selected_url = None`\n\nBut if there are any other unvisited URLs in `search_results`, you must pick the best one among those instead of returning `None`.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.judge.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "FIRE (Fact-checking with Iterative Research and Evaluation) Judge.\n\nEvaluate a single factual claim given accumulated evidence from web research.\nEither produce a final verdict if sufficient evidence exists, or generate\na search query to gather more information.\n\nDecision logic:\n- If evidence clearly supports the claim -> verdict=\"supported\"\n- If evidence clearly contradicts the claim -> verdict=\"refuted\"\n- If evidence is insufficient but a useful search is possible -> next_search=<query>\n- If no more useful searches and evidence is inconclusive -> verdict=\"not_supported\"",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "A single factual claim to verify"
        },
        {
          "prefix": "Evidence:",
          "description": "Evidence gathered from web research, may be empty initially"
        },
        {
          "prefix": "Search History:",
          "description": "Previous search queries already executed"
        },
        {
          "prefix": "Reasoning:",
          "description": "Step-by-step reasoning about the claim and evidence"
        },
        {
          "prefix": "Verdict:",
          "description": "Final judgment if enough evidence exists, otherwise None"
        },
        {
          "prefix": "Next Search:",
          "description": "Search query if more evidence needed, otherwise None. Must differ from search_history."
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "aggregator.aggregator.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Aggregate individual claim verdicts into an overall statement verdict.\n\nApply the following priority logic:\n1. If ANY claim is refuted -> CONTAINS_REFUTED_CLAIMS (highest priority)\n2. If ANY claim is not_supported -> CONTAINS_UNSUPPORTED_CLAIMS\n3. If ALL claims are supported -> SUPPORTED",
      "fields": [
        {
          "prefix": "Original Statement:",
          "description": "The original statement being evaluated"
        },
        {
          "prefix": "Claim Verdicts:",
          "description": "List of dicts with 'claim', 'verdict', and 'evidence_summary' keys"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of the aggregation logic applied"
        },
        {
          "prefix": "Overall Verdict:",
          "description": "The final verdict for the entire statement"
        },
        {
          "prefix": "Confidence:",
          "description": "Confidence score between 0.0 and 1.0"
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.11",
      "dspy": "3.0.4",
      "cloudpickle": "3.1"
    }
  }
}
