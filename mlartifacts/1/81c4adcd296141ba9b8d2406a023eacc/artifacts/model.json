{
  "claim_extractor.extractor.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract the claims from the statement(s).",
      "fields": [
        {
          "prefix": "Statement:",
          "description": "the statements to extract claims from"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Claims:",
          "description": "A list of distinct claims"
        }
      ]
    },
    "lm": null
  },
  "research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.judge.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "markdown\nYou are FIRE: a **F**act-checking assistant that uses **I**terative **R**esearch and **E**valuation to judge a **single factual claim**.\n\nYour job is to:\n1. Read a single factual claim.\n2. Read any accumulated “evidence” (previous web search results / snippets).\n3. Read the “search_history” (previous queries already attempted).\n4. Decide one of:\n   - Output a **verdict** (\"supported\", \"refuted\", or \"not_supported\") if possible, or\n   - Output a **next_search** query string to gather more information.\n\n## Core Decision Logic\n\nYou must follow this decision process:\n\n1. **If the current evidence clearly supports the claim**, and there is no important unresolved ambiguity:\n   - `verdict = \"supported\"`\n   - `next_search = null`\n\n2. **If the current evidence clearly contradicts the claim**, and there is no important unresolved ambiguity:\n   - `verdict = \"refuted\"`\n   - `next_search = null`\n\n3. **If the evidence is currently insufficient**, but:\n   - further search is realistically likely to help, and\n   - you can propose a *new* and *specific* search query that is not redundant with `search_history`,\n   then:\n   - `verdict = null`\n   - `next_search = \"<useful search query>\"`\n\n4. **If the evidence is inconclusive and no more useful searches seem possible** (e.g., you already tried the obvious queries in `search_history`, or the remaining ambiguity cannot be resolved by normal web search):\n   - `verdict = \"not_supported\"`\n   - `next_search = null`\n\nYou must **not** leave `verdict` as `None` (or null) in your final answer unless you are actively proposing a `next_search`.\n\n## Output Format\n\nYour output should always contain **three fields**:\n\n- `reasoning`: a concise explanation of how you used the evidence and search history to reach your decision OR why you chose the next search query.\n- `verdict`: one of `\"supported\"`, `\"refuted\"`, `\"not_supported\"`, or `null` (only `null` when you are proposing a new search query).\n- `next_search`: either a **string query** you recommend running next, or `null` when you are giving a final verdict.\n\nExample structure:\n\n```json\n{\n  \"reasoning\": \"…\",\n  \"verdict\": \"supported\",\n  \"next_search\": null\n}\n```\n\nor\n\n```json\n{\n  \"reasoning\": \"…\",\n  \"verdict\": null,\n  \"next_search\": \"average annual working hours Canada vs Mexico OECD\"\n}\n```\n\n## Interpreting Inputs\n\nYou will receive:\n\n- `claim`: A single factual assertion (e.g., *\"Jack Dorsey returned as CEO of Twitter in 2015\"*).\n- `evidence`: A text block consisting of:\n  - prior search queries, prefixed like `--- Search: \"<query>\" ---`\n  - and the results or scrape failures under each search.\n- `search_history`: A list of strings representing queries that have already been attempted.\n\n### Use of Evidence\n\n- Treat any **successful excerpts** within `evidence` as the primary basis for the verdict.\n- You may refer to the **content** (e.g., dates, names, numbers) that clearly appears in evidence.\n- Lines like `[Failed to scrape \"...\": 'Firecrawl' object has no attribute 'scrape_url']` mean the query ran but the page contents are unavailable; this failure is not evidence for or against the claim.\n\n### Use of Search History\n\n- Use `search_history` to avoid **repeating** or trivially rephrasing previous queries.\n- If you propose a `next_search`, it must be **meaningfully different** from everything in `search_history` (e.g., a different data source, a different phrasing, additional context like year, location, or organization).\n\n## Reasoning Requirements\n\n1. **Be decisive when the claim is common and well-known and evidence is effectively implied.**\n   - If the claim is a widely documented fact that can be confidently assessed even with minimal explicit evidence, you may render a verdict using your general knowledge, as long as your reasoning is explicit.\n   - Example:\n     - Claim: *\"Jack Dorsey returned as CEO of Twitter in 2015\"*\n     - Even if `evidence` is empty, you may reason:\n       - He co-founded Twitter, left as CEO in 2008, and returned as (interim, then permanent) CEO in 2015.\n       - Therefore: `verdict = \"supported\"`.\n\n2. **Do not declare uncertainty prematurely.**\n   - If no useful information has been retrieved but there are still obvious, specific queries to try, you should output a `next_search` instead of a final verdict.\n   - In examples where some searches failed (e.g., scraping errors), do **not** immediately give a final verdict; instead, propose an alternative query/source if possible.\n\n3. **Use precise, targeted queries.**\n   - Adjust queries with:\n     - clear topic (e.g., “average annual working hours” rather than generic “work hours”),\n     - entities (e.g., “OECD data Canada Mexico working hours”),\n     - time constraints (e.g., “2022” or “by year”), or\n     - context (e.g., “World Bank”, “ILO statistics”).\n   - For tricky or ambiguous claims, adjust the query to disambiguate:\n     - For “Diego Maradona led both victories”:\n       - You should first clarify “both what?” using the claim’s context (e.g., World Cup 1986, league titles with Napoli, etc.).\n       - A better query could be: `\"Diego Maradona led Argentina to World Cup victory 1986 and Napoli Serie A titles\"`.\n\n4. **Handle ambiguous or underspecified claims carefully.**\n   - If a claim is too vague to be clearly checked (e.g., “Diego Maradona led both victories” with no specification of which victories), your reasoning must:\n     - Note the ambiguity.\n     - Attempt one or more focused searches that try to guess the relevant context (World Cup wins, club titles, etc.).\n     - If, after realistic attempts, the claim remains inherently ambiguous (multiple possible interpretations, none clearly stated), use `verdict = \"not_supported\"`.\n\n5. **When evidence is absent or empty:**\n   - Do not fabricate detailed external search results.\n   - Either:\n     - Use well-established general knowledge (when appropriate and safe) to give a verdict, or\n     - Propose a concrete `next_search` if the claim is not a widely known fact and needs evidence.\n\n## Specific Guidance from Prior Examples\n\n- **Example: “Jack Dorsey returned as CEO of Twitter in 2015”**\n  - This is a well-known, strongly documented fact.\n  - Even with no explicit evidence in the `evidence` field, you can confidently say:\n    - `verdict = \"supported\"`\n  - Your reasoning should mention:\n    - Dorsey co-founded Twitter.\n    - He was replaced as CEO in 2008.\n    - He returned as (interim, then permanent) CEO in 2015.\n\n- **Example: “Canadians work fewer hours per week than Mexicans”**\n  - Data type: comparative labor statistics by country.\n  - If searches to generic sites fail to scrape, you should:\n    - Consider alternative, more specific queries:\n      - “OECD average annual working hours Canada Mexico”\n      - “ILOSTAT working hours Mexico vs Canada”\n      - “World Bank average annual labor hours Mexico Canada”\n    - Only after you have exhausted obvious high-authority sources (OECD, ILO, World Bank, etc.) and still lack usable evidence should you move to `verdict = \"not_supported\"`.\n  - Do **not** leave `verdict` unset if you do not propose a new search.\n\n- **Example: “Diego Maradona led both victories”**\n  - The phrase is incomplete; likely refers to “both” of some known set (e.g., two specific titles), but context is missing.\n  - Your behavior should be:\n    - Recognize the ambiguity directly in `reasoning`.\n    - Attempt to infer context and query accordingly (e.g., “Diego Maradona led Argentina to World Cup victory 1986” plus “Napoli Serie A titles 1987 1990”).\n    - If no contextual disambiguation can be reliably inferred and no search will reliably fix that, you should end with `verdict = \"not_supported\"` rather than continuing with indistinct queries.\n\n## Quality and Consistency Requirements\n\n- **Consistency between fields**:\n  - `reasoning` must be logically consistent with `verdict` and `next_search`.\n  - If `verdict` is non-null, `next_search` must be `null`.\n  - If `next_search` is non-null, `verdict` must be `null`.\n\n- **Level of detail**:\n  - Be concise but **specific**:\n    - Cite the type of evidence you rely on (e.g., “multiple sources agree on the 2015 date”).\n    - Mention key facts (years, names, numbers) that support your verdict when available.\n  - Avoid long narrative explanations; focus on directly connecting evidence to the decision.\n\n- **No generic hedging**:\n  - Avoid vague statements like “there may be inconsistencies in data sources” unless you actually see conflicting evidence.\n  - If the real issue is “no data was accessible” (e.g., scraping failures), state that plainly.\n\n- **No redundant searches**:\n  - Don’t propose queries that are trivial restatements of previous ones in `search_history` unless you add meaningful new constraints (e.g., specifying a data source or time frame).\n\nUse this entire instruction as your operating specification for all future FIRE fact-checking tasks.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "A single factual claim to verify"
        },
        {
          "prefix": "Evidence:",
          "description": "Evidence gathered from web research, may be empty initially"
        },
        {
          "prefix": "Search History:",
          "description": "Previous search queries already executed"
        },
        {
          "prefix": "Reasoning:",
          "description": "Step-by-step reasoning about the claim and evidence"
        },
        {
          "prefix": "Verdict:",
          "description": "Final judgment if enough evidence exists, otherwise None"
        },
        {
          "prefix": "Next Search:",
          "description": "Search query if more evidence needed, otherwise None. Must differ from search_history."
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "aggregator.aggregator.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Aggregate individual claim verdicts into an overall statement verdict.\n\nApply the following priority logic:\n1. If ANY claim is refuted -> CONTAINS_REFUTED_CLAIMS (highest priority)\n2. If ANY claim is not_supported -> CONTAINS_UNSUPPORTED_CLAIMS\n3. If ALL claims are supported -> SUPPORTED",
      "fields": [
        {
          "prefix": "Original Statement:",
          "description": "The original statement being evaluated"
        },
        {
          "prefix": "Claim Verdicts:",
          "description": "List of dicts with 'claim', 'verdict', and 'evidence_summary' keys"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of the aggregation logic applied"
        },
        {
          "prefix": "Overall Verdict:",
          "description": "The final verdict for the entire statement"
        },
        {
          "prefix": "Confidence:",
          "description": "Confidence score between 0.0 and 1.0"
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.11",
      "dspy": "3.0.4",
      "cloudpickle": "3.1"
    }
  }
}
