{
  "claim_extractor.extractor.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "You are given one or more natural-language statements. Your task is to extract *claims* from these statements.\n\nA *claim* is any declarative statement that asserts something that could, in principle, be true or false (i.e., it is fact-checkable). Your output should list these claims explicitly.\n\nFollow these guidelines:\n\n1. **Input format**\n   - You will receive an input field named `statement` containing one or more sentences.\n   - Example:\n     - statement: \"Canadians work fewer hours per week than Mexicans\"\n\n2. **What counts as a claim**\n   - The sentence must:\n     - Be declarative (not a question, command, or exclamation).\n     - Assert something that can be evaluated as true or false.\n   - Examples that *are* claims:\n     - \"Canadians work fewer hours per week than Mexicans\"\n     - \"Not all Mexicans are members of the same church\"\n     - \"The New Populism advocated for the direct election of senators\"\n   - Examples that are *not* claims:\n     - Questions: \"Do Canadians work fewer hours than Mexicans?\"\n     - Commands: \"Work fewer hours per week.\"\n     - Purely subjective expressions without an asserted fact: \"Mexican food is the best\" (unless the task context explicitly treats such value judgments as claims; if unsure, include them as claims).\n\n3. **Granularity**\n   - If the entire statement is a single coherent claim, extract it as one claim.\n   - Do *not* split a simple sentence into multiple smaller claims unless it clearly contains multiple distinct, fact-checkable assertions that could be evaluated independently.\n   - Do *not* merge logically separate claims from multi-sentence inputs; each distinct fact-like assertion should be a separate item in the `claims` list.\n\n4. **Rephrasing**\n   - Prefer to use the original wording of the claim as it appears in the input.\n   - Minor normalization (e.g., fixing obvious grammatical slips) is acceptable, but do not change the substantive meaning.\n\n5. **Neutrality to evidence**\n   - Your task is *only* to identify and extract claims from the text.\n   - Do **not** attempt to determine whether the claims are true, false, supported, contradicted, or unknown.\n   - You may internally reason about what the statement is asserting, but your final `claims` output must not include any classification labels or truth judgments.\n\n6. **Output format**\n   - Always produce two top-level fields: `reasoning` and `claims`.\n   - `reasoning`: Briefly explain how you identified the claim(s) from the input statement(s). Keep it short and focused on the structure/content of the statement, not its truth.\n   - `claims`: A JSON-style list of strings, where each string is one extracted claim.\n   - If there are no claims, return an empty list for `claims`.\n\n7. **Examples**\n\n   - Example 1\n     - Input:\n       - statement: \"Canadians work fewer hours per week than Mexicans\"\n     - Output:\n       - reasoning: The statement asserts a comparative fact about average weekly work hours between Canadians and Mexicans, which is a single, clear, fact-checkable claim.\n       - claims: [\"Canadians work fewer hours per week than Mexicans\"]\n\n   - Example 2\n     - Input:\n       - statement: \"Not all Mexicans are members of the same church\"\n     - Output:\n       - reasoning: The sentence asserts a general fact about religious diversity among Mexicans, which is a single, fact-checkable claim.\n       - claims: [\"Not all Mexicans are members of the same church\"]\n\n   - Example 3\n     - Input:\n       - statement: \"The New Populism advocated for the direct election of senators\"\n     - Output:\n       - reasoning: The statement attributes a specific political stance to the New Populism movement, which is a clear, fact-checkable claim.\n       - claims: [\"The New Populism advocated for the direct election of senators\"]",
      "fields": [
        {
          "prefix": "Statement:",
          "description": "the statements to extract claims from"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Claims:",
          "description": "A list of distinct claims"
        }
      ]
    },
    "lm": null
  },
  "research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.judge.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "FIRE (Fact-checking with Iterative Research and Evaluation) Judge.\n\nEvaluate a single factual claim given accumulated evidence from web research.\nEither produce a final verdict if sufficient evidence exists, or generate\na search query to gather more information.\n\nDecision logic:\n- If evidence clearly supports the claim -> verdict=\"supported\"\n- If evidence clearly contradicts the claim -> verdict=\"refuted\"\n- If evidence is insufficient but a useful search is possible -> next_search=<query>\n- If no more useful searches and evidence is inconclusive -> verdict=\"not_supported\"",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "A single factual claim to verify"
        },
        {
          "prefix": "Evidence:",
          "description": "Evidence gathered from web research, may be empty initially"
        },
        {
          "prefix": "Search History:",
          "description": "Previous search queries already executed"
        },
        {
          "prefix": "Reasoning:",
          "description": "Step-by-step reasoning about the claim and evidence"
        },
        {
          "prefix": "Verdict:",
          "description": "Final judgment if enough evidence exists, otherwise None"
        },
        {
          "prefix": "Next Search:",
          "description": "Search query if more evidence needed, otherwise None. Must differ from search_history."
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "aggregator.aggregator.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Aggregate individual claim verdicts into an overall statement verdict.\n\nApply the following priority logic:\n1. If ANY claim is refuted -> CONTAINS_REFUTED_CLAIMS (highest priority)\n2. If ANY claim is not_supported -> CONTAINS_UNSUPPORTED_CLAIMS\n3. If ALL claims are supported -> SUPPORTED",
      "fields": [
        {
          "prefix": "Original Statement:",
          "description": "The original statement being evaluated"
        },
        {
          "prefix": "Claim Verdicts:",
          "description": "List of dicts with 'claim', 'verdict', and 'evidence_summary' keys"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of the aggregation logic applied"
        },
        {
          "prefix": "Overall Verdict:",
          "description": "The final verdict for the entire statement"
        },
        {
          "prefix": "Confidence:",
          "description": "Confidence score between 0.0 and 1.0"
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.11",
      "dspy": "3.0.4",
      "cloudpickle": "3.1"
    }
  }
}
