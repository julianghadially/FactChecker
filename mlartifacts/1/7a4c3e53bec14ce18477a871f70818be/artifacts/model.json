{
  "claim_extractor.extractor.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract the claims from the statement(s).",
      "fields": [
        {
          "prefix": "Statement:",
          "description": "the statements to extract claims from"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Claims:",
          "description": "A list of distinct claims"
        }
      ]
    },
    "lm": null
  },
  "research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.judge.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "FIRE (Fact-checking with Iterative Research and Evaluation) Judge.\n\nEvaluate a single factual claim given accumulated evidence from web research.\nEither produce a final verdict if sufficient evidence exists, or generate\na search query to gather more information.\n\nDecision logic:\n- If evidence clearly supports the claim -> verdict=\"supported\"\n- If evidence clearly contradicts the claim -> verdict=\"refuted\"\n- If evidence is insufficient but a useful search is possible -> next_search=<query>\n- If no more useful searches and evidence is inconclusive -> verdict=\"not_supported\"",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "A single factual claim to verify"
        },
        {
          "prefix": "Evidence:",
          "description": "Evidence gathered from web research, may be empty initially"
        },
        {
          "prefix": "Search History:",
          "description": "Previous search queries already executed"
        },
        {
          "prefix": "Reasoning:",
          "description": "Step-by-step reasoning about the claim and evidence"
        },
        {
          "prefix": "Verdict:",
          "description": "Final judgment if enough evidence exists, otherwise None"
        },
        {
          "prefix": "Next Search:",
          "description": "Search query if more evidence needed, otherwise None. Must differ from search_history."
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.page_selector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Select the most promising page to visit from search results for evidence gathering.\n\nGiven a claim being fact-checked and search results, intelligently select which\npage to visit next based on relevance, authoritativeness, and potential to\nprovide supporting or refuting evidence.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Search Results:",
          "description": "Search results with 'title', 'link', 'snippet' fields"
        },
        {
          "prefix": "Visited Urls:",
          "description": "URLs already visited in this research session"
        },
        {
          "prefix": "Current Evidence:",
          "description": "Evidence already gathered from previous pages"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of why this page is most relevant to the claim"
        },
        {
          "prefix": "Selected Url:",
          "description": "URL to visit next, or None if existing evidence is sufficient or no useful pages remain unvisited"
        }
      ]
    },
    "lm": null
  },
  "fire_judge.research_agent.evidence_summarizer.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Extract and summarize evidence relevant to verifying a specific claim.\n\nGiven a claim and scraped web page content, identify and extract facts\nthat either support or refute the claim. Focus on factual information\nwith proper source attribution.",
      "fields": [
        {
          "prefix": "Claim:",
          "description": "The factual claim being verified"
        },
        {
          "prefix": "Page Content:",
          "description": "Markdown content scraped from the web page"
        },
        {
          "prefix": "Source Url:",
          "description": "URL of the source page for attribution"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Relevant Evidence:",
          "description": "Extracted facts relevant to the claim, with source attribution"
        },
        {
          "prefix": "Evidence Stance:",
          "description": "Whether this evidence 'supports', 'refutes', or is 'neutral' toward the claim"
        }
      ]
    },
    "lm": null
  },
  "aggregator.aggregator.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "You are given:\n1. An `original_statement` (a natural language sentence or short passage).\n2. A list called `claim_verdicts`, where each element is an object with at least:\n   - `claim`: the text of a specific claim extracted from the original statement.\n   - `verdict`: one of the strings `\"supported\"`, `\"not_supported\"`, or `\"refuted\"`.\n   - `evidence_summary`: a (possibly empty) string summarizing how that claim-level verdict was reached.\n\nYour task is to aggregate these individual claim verdicts into a single overall verdict for the entire original statement, and to provide brief reasoning and a confidence score.\n\nFollow this logic exactly, in this priority order:\n\n1. If ANY claim in `claim_verdicts` has `verdict == \"refuted\"`, then:\n   - `overall_verdict` must be `\"CONTAINS_REFUTED_CLAIMS\"`.\n   - This has the highest priority and overrides all other possibilities, regardless of any supported or unsupported claims.\n\n2. Otherwise, if NO claim is refuted but AT LEAST ONE claim has `verdict == \"not_supported\"`, then:\n   - `overall_verdict` must be `\"CONTAINS_UNSUPPORTED_CLAIMS\"`.\n\n3. Otherwise, if ALL claims have `verdict == \"supported\"`, then:\n   - `overall_verdict` must be `\"SUPPORTED\"`.\n\nThere are no other valid overall verdict labels besides:\n- `\"CONTAINS_REFUTED_CLAIMS\"`\n- `\"CONTAINS_UNSUPPORTED_CLAIMS\"`\n- `\"SUPPORTED\"`\n\nDo NOT invent new labels or modify their spelling or casing.\n\n---\n\nOutput format\nYou must produce exactly three top-level fields:\n\n1. `reasoning`\n2. `overall_verdict`\n3. `confidence`\n\nUse this structure:\n\n- `reasoning`: A short paragraph (2–4 sentences) that:\n  - Explicitly references the relevant claim verdicts (e.g., “The claim X is supported …” or “One claim is not supported due to lack of evidence …”).\n  - Clearly ties the chosen `overall_verdict` to the specified priority rules (e.g., “since there is at least one unsupported claim, the overall verdict is …”).\n  - Focuses on the aggregation logic, not on re-evaluating the factual content or the evidence itself.\n\n  Keep this concise and deterministic. Do not describe web search errors or scraping failures except insofar as they explain why a claim is “not_supported” (e.g., “there was insufficient evidence to substantiate the claim”).\n\n- `overall_verdict`: A single string, exactly one of:\n  - `SUPPORTED`\n  - `CONTAINS_UNSUPPORTED_CLAIMS`\n  - `CONTAINS_REFUTED_CLAIMS`\n\n- `confidence`: A numeric value between 0 and 1 indicating how confident you are that you applied the aggregation rules correctly. In this task, you are not judging truth, only aggregation, so:\n  - Use `1.0` when the mapping from claim-level verdicts to the overall verdict is straightforward and unambiguous (e.g., a single supported claim, or a clear mix that directly matches a rule).\n  - You may use a slightly lower score (e.g., `0.8`) only if there is some structural ambiguity in the input (e.g., unclear or malformed verdict labels). Do NOT lower confidence because of uncertainty about the underlying real-world facts; that is already encoded in the claim-level verdicts.\n\n---\n\nAdditional guidelines\n\n- Never override or reinterpret a claim-level `verdict`. Treat `supported`, `not_supported`, and `refuted` as given and final.\n- Apply the priority rules mechanically:\n  - Always check for any `\"refuted\"` claim first.\n  - Only if none are refuted, check for any `\"not_supported\"` claim.\n  - Only if all are `\"supported\"`, choose `\"SUPPORTED\"`.\n- Handle single-claim inputs as a special case of the same rules:\n  - One supported claim → `SUPPORTED`.\n  - One not_supported claim → `CONTAINS_UNSUPPORTED_CLAIMS`.\n  - One refuted claim → `CONTAINS_REFUTED_CLAIMS`.\n- Do not add extra sections or fields to the output. Only return `reasoning`, `overall_verdict`, and `confidence`.",
      "fields": [
        {
          "prefix": "Original Statement:",
          "description": "The original statement being evaluated"
        },
        {
          "prefix": "Claim Verdicts:",
          "description": "List of dicts with 'claim', 'verdict', and 'evidence_summary' keys"
        },
        {
          "prefix": "Reasoning:",
          "description": "Explanation of the aggregation logic applied"
        },
        {
          "prefix": "Overall Verdict:",
          "description": "The final verdict for the entire statement"
        },
        {
          "prefix": "Confidence:",
          "description": "Confidence score between 0.0 and 1.0"
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.11",
      "dspy": "3.0.4",
      "cloudpickle": "3.1"
    }
  }
}
